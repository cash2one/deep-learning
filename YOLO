最近读了一篇大神的大作《You Only Look Once:Unified, Real-Time Object Detection》，试着写一下学到的东西。
YOLO是在物体检测领域最新的一篇文章，在识别速度方面现在是state-of-art级别。能达到45fps,faster YOLO能达到150fps。
首先说一下目标检测的三个指标：识别精度、识别效率、定位准确性。
识别精度是用mAP（mean average precision）来衡量。
YOLO就是在识别效率方面发力的一篇大神级文章。
一. YOLO与R-CNN不同的地方：
R-CNN处理区域块是用的图片分割，把图片分成2K个小图片，在小图片上进行目标的识别，而YOLO是直接操作一整张原图，在原图上划出若干个格子。
R-CNN处理一张图片用上千个网络综合出结果，而YOLO就用一个网络，直接出结果。
R-CNN的流程是先确定bounding box,然后用CNN训练特征（4096维），然后用每个类别的SVM得到属于某个类别的概率。
YOLO是在CNN中直接生成回归bounding box的参数和某区域属于所有类别中某一个的概率。
所有YOLO的速度是R-CNN的1000倍，是FASTER R-CNN的100倍。完全可以达到实时检测级别。
二. YOLO的基本原理

YOLO是把图片分成S×S个网格，若某物体的中心落在该网格内，就用该网格负责该物体的识别。
在每个网格中有B个边界框（bounding box），用来圈出物体的范围。每个边界框需要预测五个值（x,y,w,h,confidence）。
x,y是边界框中心点的坐标。w,h是边界框的长和高。confidence是边界框内是某物体的置信度。
confidence=P(object)*IOU(truth,pred)，其中P(object)是网格内有无目标物体的情况（若有则为1，否则为0）
IOU(truth,pred)是边界框区域与已经标注的物体范围的IOU值
解释一下IOU：设有A、B两个区域，则IOU(A,B)=（A交B）/（A并B）即为重叠区域与并集的比例。
除此之外，每个网格还要预测一个目标物体的类别信息C，即网格内物体属于某个类别的概率。
所以网络要预测的值的个数为：S×S×（B×5+C）个，即网络的输出为S×S×[(B*5+C)]shape的三维矩阵。

**这里插播几句**
在运行YOLO之前我先安装了opencv 和CUDA
安装opencv的时候，去观望下载一个opencv3.0.zip，解压之后，直接make,make install就可以了。
但是出了个问题，在运行的时候报了一个错，找不到libopencv_highgui.so.3.0，但是我find了一下，在/usr/local/lib/里面
在/etc/ld.so。conf.d/中写了一个文件opencv.conf，吧路径写进去了，运行一下sudo ldconf 就可以了，不知道什么原因。。。

然后按抓给你CUDA，这是NVIDIA的一个运行GPU跑程序的库...
